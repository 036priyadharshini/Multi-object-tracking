# -*- coding: utf-8 -*-
"""MOT1720_logging_intermediate_results (2).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12muCuh7zu0Xls4AGkw7RkWfbW1klmGTg
"""

# Commented out IPython magic to ensure Python compatibility.
!git clone https://github.com/vukasin-stanojevic/BoostTrack.git
# %cd BoostTrack

pip install -r requirements.txt

from google.colab import drive
drive.mount('/content/drive')

!mkdir -p /content/BoostTrack/data
!ln -s /content/drive/MyDrive/BoostTrack/data/MOT17 /content/BoostTrack/data/MOT17
!ln -s /content/drive/MyDrive/BoostTrack/data/MOT20 /content/BoostTrack/data/MOT20

!rm -rf /content/BoostTrack/data/MOT17
!rm -rf /content/BoostTrack/data/MOT20

!ln -s /content/drive/MyDrive/BoostTrack/data/MOT17 /content/BoostTrack/data/MOT17
!ln -s /content/drive/MyDrive/BoostTrack/data/MOT20 /content/BoostTrack/data/MOT20

"""Finding training file"""

!find /content/BoostTrack/ -name train.py

!mkdir -p /content/BoostTrack/external/weights
!ln -s /content/drive/MyDrive/BoostTrack/weights/* /content/BoostTrack/external/weights/

import sys
sys.path.append("/content/BoostTrack")

import os
os.environ["PYTHONPATH"] = "/content/BoostTrack"

!pip install torchreid

!pip install yacs

!find /content/BoostTrack -name "requirements.txt"

!pip install -r /content/BoostTrack/external/deep-person-reid/requirements.txt

!grep -r "faiss-gpu" /content/BoostTrack/

!pip install lap

"""THE BELOW LINE WILL ASK YOU TO RESTART THE SESSION. DO NOT DO IT."""

!pip install -U pip setuptools wheel

!pip install -U pip setuptools wheel numpy cython torch torchvision onnx onnxruntime

import sys
sys.path.append("/content/YOLOX")  # Adjust this path if needed

!pip uninstall -y yolox onnx

!pip install onnx==1.14.1

!pip uninstall -y yolox onnx onnxruntime onnx-simplifier

!pip install onnx==1.14.1

!pip install --no-deps yolox

!python -c "import yolox; print('YOLOX installed successfully!')"

!pip install loguru

!python -c "import loguru; print('Loguru installed successfully!')"

!pip install thop

!mkdir -p /content/BoostTrack/external/YOLOX/YOLOX_outputs/yolox_s/
!wget -O /content/BoostTrack/external/YOLOX/YOLOX_outputs/yolox_s/best_ckpt.pth \
    https://github.com/Megvii-BaseDetection/YOLOX/releases/download/0.1.1rc0/yolox_s.pth

!mkdir -p /content/BoostTrack/external/YOLOX/YOLOX_outputs/yolox_s/
!wget -O /content/BoostTrack/external/YOLOX/YOLOX_outputs/yolox_s/best_ckpt.pth \
    https://github.com/Megvii-BaseDetection/YOLOX/releases/download/0.1.1rc0/yolox_s.pth

!python3 /content/BoostTrack/external/YOLOX/tools/train.py \
    -f /content/BoostTrack/external/YOLOX/exps/example/custom/yolox_s.py \
    -d 1 -b 16 --fp16 -o

"""Set self.num_classes to 80  in yolox_s.py"""

!mkdir -p /content/BoostTrack/external/YOLOX/YOLOX_outputs/yolox_s/vis_res/

!mkdir -p /content/BoostTrack/external/YOLOX/YOLOX_outputs/yolox_s/vis_res/

!chmod -R 777 /content/BoostTrack/external/YOLOX/YOLOX_outputs/yolox_s/vis_res/

!pip uninstall -y opencv-python opencv-python-headless
!pip install opencv-python-headless

import os
os.environ["QT_QPA_PLATFORM"] = "offscreen"

import os
print(os.path.exists("/content/BoostTrack/3105196-uhd_3840_2160_30fps.mp4"))

"""NEW VIDEO SAMPLE OUTPUT"""

!pip install -r requirements.txt

!cd /content/BoostTrack

!python3 external/YOLOX/tools/train.py -f external/YOLOX/exps/default/yolox_s.py -d 1 -b 8 --fp16 -o

"""TO GET OUTPUT OF PROCESSING IN EACH STEP"""

# Step 1: Upload your video
from google.colab import files
uploaded = files.upload()  # Upload your .mp4 file manually

# Step 2: Move it to BoostTrack path
import os
uploaded_filename = list(uploaded.keys())[0]  # Get uploaded file name
target_path = "/content/BoostTrack/my_video.mp4"
os.rename(uploaded_filename, target_path)
print(f"Moved {uploaded_filename} to {target_path}")



# Step 4: Run YOLOX video detection
!python3 /content/BoostTrack/external/YOLOX/tools/demo.py video \
--exp_file /content/BoostTrack/external/YOLOX/exps/example/custom/yolox_s.py \
--path /content/BoostTrack/my_video.mp4 \
--device cuda \
--ckpt /content/BoostTrack/external/YOLOX/YOLOX_outputs/yolox_s/best_ckpt.pth \
--conf 0.3 --nms 0.3 --save_result

!find /content/BoostTrack/YOLOX_outputs/ -name "*.mp4"

!ffmpeg -y -i /content/BoostTrack/YOLOX_outputs/yolox_s/vis_res/my_video.mp4 \
-vcodec libx264 -pix_fmt yuv420p /content/BoostTrack/output_fixed.mp4

!ffprobe -v error -show_entries format=duration -of default=noprint_wrappers=1:nokey=1 /content/BoostTrack/my_video.mp4

!grep -i "VideoWriter" /content/BoostTrack/external/YOLOX/tools/demo.py

!grep -r "\.write(" /content/BoostTrack/

!find /content/BoostTrack -name "demo.py"

!python3 /content/BoostTrack/external/YOLOX/tools/demo.py \
video \
-f /content/BoostTrack/exps/example/yolox_voc/yolox_s.py \
-c /content/BoostTrack/YOLOX_outputs/yolox_s/best_ckpt



from google.colab import files
uploaded = files.upload()

!mv 3105196-uhd_3840_2160_30fps.mp4 /content/BoostTrack/my_video.mp4

!rm -rf /content/BoostTrack/YOLOX_outputs/yolox_s/vis_res/*

!python3 /content/BoostTrack/external/YOLOX/tools/demo.py \
video \
-f /content/BoostTrack/external/YOLOX/exps/example/custom/yolox_s.py \
-c /content/BoostTrack/external/YOLOX/YOLOX_outputs/yolox_s/best_ckpt.pth \
--path /content/BoostTrack/my_video.mp4 \
--conf 0.3 --nms 0.3 --save_result \
--device cuda

!ffmpeg -y -i $(find /content/BoostTrack/YOLOX_outputs/yolox_s/vis_res/ -name "my_video.mp4" | tail -n 1) \
-vcodec libx264 -pix_fmt yuv420p /content/BoostTrack/output_fixed.mp4

from google.colab import files
files.download("/content/BoostTrack/output_fixed.mp4")

!python /content/BoostTrack/external/YOLOX/tools/demo.py \
--demo video \
--experiment-name yolox_s \
--path /content/BoostTrack/my_video.mp4 \
--save_result \
--exp_file /content/BoostTrack/external/YOLOX/exps/example/custom/yolox_s.py \
--ckpt /content/BoostTrack/external/YOLOX/YOLOX_outputs/yolox_s/best_ckpt.pth \
--device cuda \
--conf 0.3 \
--nms 0.3

!python3 /content/BoostTrack/external/YOLOX/tools/demo.py \
video \
-f /content/BoostTrack/external/YOLOX/exps/example/custom/yolox_s.py \
-c /content/BoostTrack/external/YOLOX/YOLOX_outputs/yolox_s/best_ckpt.pth \
--path /content/BoostTrack/my_video.mp4 \
--conf 0.3 --nms 0.3 --save_result \
--device cuda

!find /content/BoostTrack -name ".csv"

!python /content/BoostTrack/external/YOLOX/tools/demo.py video \
--experiment-name yolox_s \
--path /content/BoostTrack/my_video.mp4 \
--save_result \
--exp_file /content/BoostTrack/external/YOLOX/exps/example/custom/yolox_s.py \
--ckpt /content/BoostTrack/external/YOLOX/YOLOX_outputs/yolox_s/best_ckpt.pth \
--device cuda \
--conf 0.3 \
--nms 0.3

!python /content/BoostTrack/external/YOLOX/tools/demo.py \
video \
--experiment-name yolox_s \
--path /content/BoostTrack/my_video.mp4 \
--save_result \
--exp_file /content/BoostTrack/external/YOLOX/exps/example/custom/yolox_s.py \
--ckpt /content/BoostTrack/external/YOLOX/YOLOX_outputs/yolox_s/best_ckpt.pth \
--device cuda \
--conf 0.3 \
--nms 0.3

!ls -l /content/BoostTrack/YOLOX_outputs/yolox_s/vis_res/confidence_log.csv

!cat /content/BoostTrack/YOLOX_outputs/yolox_s/vis_res/confidence_log.csv

#import pandas as pd
import matplotlib.pyplot as plt
import ast

# Load CSV
df = pd.read_csv("/content/BoostTrack/YOLOX_outputs/yolox_s/vis_res/confidence_log.csv")

# Convert string representation of list into actual list
df['confidences'] = df['confidences'].apply(ast.literal_eval)

# Find max number of detections in any frame
max_detections = df['confidences'].apply(len).max()

plt.figure(figsize=(12, 6))

# For each detection index, plot confidence over frames
for idx in range(max_detections):
    # Extract confidence for detection idx across frames (NaN if missing)
    confidences = df['confidences'].apply(lambda x: x[idx] if len(x) > idx else None)
    plt.plot(df['frame'], confidences, label=f'Detection {idx}')

plt.xlabel('Frame')
plt.ylabel('Confidence')
plt.title('Confidence of each detection index over frames')
plt.legend()
plt.grid(True)
plt.show()

import os
print("Current working directory:", os.getcwd())

!rm -rf /content/BoostTrack/.git

!du -h /content/BoostTrack --max-depth=2 | sort -hr | head -20

!cp /content/BoostTrack/boosttrack.py /content/drive/MyDrive/boosttrack_backup.py

!python /content/BoostTrack/external/YOLOX/tools/demo.py \
video \
--experiment-name yolox_s \
--path /content/BoostTrack/my_video.mp4 \
--save_result \
--exp_file /content/BoostTrack/external/YOLOX/exps/example/custom/yolox_s.py \
--ckpt /content/BoostTrack/external/YOLOX/YOLOX_outputs/yolox_s/best_ckpt.pth \
--device cuda \
--conf 0.3 \
--nms 0.3

!rm -rf /content/BoostTrack/cache/*

!find /content/BoostTrack -type d -name "cache" -exec rm -rf {} +

!rm -f /content/BoostTrack/confidence_log.csv

import shutil
shutil.rmtree("/content/BoostTrack/external/torchreid/cache", ignore_errors=True)
print("Embedding cache cleared.")

import shutil

shutil.rmtree("/content/BoostTrack/external/torchreid/cache", ignore_errors=True)
shutil.rmtree("/content/BoostTrack/external/YOLOX/ECC_cache", ignore_errors=True)  # if ECC used
print("All caches cleared.")

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/BoostTrack/external
!git clone https://github.com/JDAI-CV/fast-reid.git

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/BoostTrack/external/fast-reid
!pip install -r requirements.txt
!pip install -e .

import fastreid
print("✅ FastReID is now installed.")

!ls -l /content/BoostTrack/confidence_log.csv

import cv2
import pandas as pd
import os

# === CONFIG ===
track_id = 9
video_path = "/content/BoostTrack/my_video.mp4"
bbox_log = "/content/BoostTrack/bbox_log.csv"
conf_log = "/content/BoostTrack/confidence_log.csv"
out_dir = "/content/track9_annotations"

os.makedirs(out_dir, exist_ok=True)

# === Load logs ===
bbox_df = pd.read_csv(bbox_log, on_bad_lines='skip')
conf_df = pd.read_csv(conf_log)

# Filter track_id
bbox_track = bbox_df[bbox_df["track_id"] == track_id]
conf_track = conf_df[conf_df["track_id"] == track_id]

# Group by frame
bbox_dict = (
    bbox_track.groupby("frame", group_keys=False)
    .apply(lambda g: g.iloc[0])
    .to_dict(orient="index")
)

conf_dict = (
    conf_track.sort_values("frame")
    .groupby("frame", as_index=False)
    .last()
    .set_index("frame")
    .to_dict(orient="index")
)
sbiou_dict = (
    sbiou_track.sort_values("frame")
    .groupby("frame", as_index=False)
    .last()
    .set_index("frame")
    .to_dict(orient="index")
)
# === Annotate video ===
cap = cv2.VideoCapture(video_path)
frame_id = 0

while True:
    ret, frame = cap.read()
    if not ret:
        break

    if frame_id in conf_dict:
        conf = conf_dict[frame_id]["confidence"]
        matched = conf_dict[frame_id]["match_status"] == 1
        color = (0, 255, 0) if matched else (0, 0, 255)  # Green if matched, Red if occluded

        # Try to get the current or last known bbox
        if frame_id in bbox_dict:
            box = bbox_dict[frame_id]
        else:
            past_frames = [f for f in bbox_dict if f < frame_id]
            if past_frames:
                last = max(past_frames)
                box = bbox_dict[last]
            else:
                frame_id += 1
                continue  # Skip frame if no bbox info

        x1, y1, x2, y2 = int(box["x1"]), int(box["y1"]), int(box["x2"]), int(box["y2"])

        # Build label: ID + confidence + occluded status
        label = f"ID {track_id} | Conf: {conf:.2f}"
        if not matched:
            label += " (occluded)"

        cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
        cv2.putText(frame, label, (x1, y1 - 8), cv2.FONT_HERSHEY_SIMPLEX, 0.55, color, 2)

    # Save frame
    out_path = os.path.join(out_dir, f"frame_{frame_id:03}.jpg")
    cv2.imwrite(out_path, frame)

    frame_id += 1

cap.release()
print(f"✅ Annotated frames saved in: {out_dir}")

with open("/content/BoostTrack/confidence_log.csv", "r") as f:
    print(f.readline())  # prints the header row

!python /content/BoostTrack/run_boosttrack.py \
--video_path /content/BoostTrack/my_video.mp4 \
--exp_file /content/BoostTrack/external/YOLOX/exps/example/custom/yolox_s.py \
--ckpt_path /content/BoostTrack/external/YOLOX/YOLOX_outputs/yolox_s/best_ckpt.pth

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load CSVs
confidence_df = pd.read_csv("/content/BoostTrack/confidence_log.csv")
occlusion_df = pd.read_csv("/content/BoostTrack/occlusion_log.csv")

# === Choose a specific track_id to visualize ===
track_id_to_plot = 9  # Change to any track ID you'd like to investigate

# Filter data for this track
track_data = confidence_df[confidence_df["track_id"] == track_id_to_plot]
track_data = track_data.sort_values("frame")

# Merge occlusion info for marking
occlusion_data = occlusion_df[occlusion_df["track_id"] == track_id_to_plot]
occluded_frames = occlusion_data["frame"].tolist()

# Plot confidence decay
plt.figure(figsize=(12, 5))
sns.lineplot(x="frame", y="confidence", data=track_data, marker="o", label="Confidence")

# Highlight occlusion frames
for frame in occluded_frames:
    plt.axvline(x=frame, color="red", linestyle="--", alpha=0.5, label="Occluded" if frame == occluded_frames[0] else "")

# Highlight match status
matched_frames = track_data[track_data["match_status"] == 1]["frame"]
unmatched_frames = track_data[track_data["match_status"] == 0]["frame"]

plt.scatter(matched_frames, track_data[track_data["match_status"] == 1]["confidence"], color="green", label="Matched")
plt.scatter(unmatched_frames, track_data[track_data["match_status"] == 0]["confidence"], color="orange", label="Unmatched")

plt.title(f"Tracklet Confidence Over Time — Track ID {track_id_to_plot}")
plt.xlabel("Frame")
plt.ylabel("Confidence")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

import pandas as pd
import cv2
import os

# === Setup ===
video_path = "/content/BoostTrack/my_video.mp4"
bbox_log_path = "/content/BoostTrack/bbox_log.csv"
output_dir = "/content/track9_crops"
track_id = 9

os.makedirs(output_dir, exist_ok=True)

# === Load bounding box data ===
df = pd.read_csv(bbox_log_path, on_bad_lines='skip')
track_df = df[df["track_id"] == track_id].sort_values("frame")

# === Open the video ===
cap = cv2.VideoCapture(video_path)
total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
frame_index = 0

# === Loop over video frames ===
while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    if frame_index in track_df["frame"].values:
        rows = track_df[track_df["frame"] == frame_index]
        for i, row in rows.iterrows():
            x1, y1, x2, y2 = int(row["x1"]), int(row["y1"]), int(row["x2"]), int(row["y2"])
            crop = frame[y1:y2, x1:x2]
            out_path = os.path.join(output_dir, f"track{track_id}_frame{frame_index}.jpg")
            cv2.imwrite(out_path, crop)

    frame_index += 1

cap.release()
print(f"✅ Crops saved to: {output_dir}")

!rm -rf /content/track9_annotated

!print(f"[DEBUG] Frame {self.frame_count}: Active Trackers = {[t.id for t in self.trackers]}")

import cv2
import pandas as pd
import os

track_id = 9
video_path = "/content/BoostTrack/my_video.mp4"
bbox_log = "/content/BoostTrack/bbox_log.csv"
sbiou_log = "/content/BoostTrack/sbiou_log.csv"
conf_log = "/content/BoostTrack/confidence_log.csv"
out_dir = "/content/track9_annotated"

os.makedirs(out_dir, exist_ok=True)

# Load CSVs
bbox_df = pd.read_csv(bbox_log)
sbiou_df = pd.read_csv(sbiou_log)
conf_df = pd.read_csv(conf_log)

# Filter by track_id
bbox_track = bbox_df[bbox_df["track_id"] == track_id]
conf_track = conf_df[conf_df["track_id"] == track_id]
sbiou_track = sbiou_df[sbiou_df["frame"].isin(conf_track["frame"])]

# Group by frame
bbox_dict = (
    bbox_track.groupby("frame", group_keys=False)
    .apply(lambda g: g.iloc[0])
    .to_dict(orient="index")
)

conf_dict = (
    conf_track.sort_values("frame")
    .groupby("frame", as_index=False)
    .last()
    .set_index("frame")
    .to_dict(orient="index")
)
sbiou_dict = (
    sbiou_track.sort_values("frame")
    .groupby("frame", as_index=False)
    .last()
    .set_index("frame")
    .to_dict(orient="index")
)


# Open video
cap = cv2.VideoCapture(video_path)
frame_id = 0
while True:
    ret, frame = cap.read()
    if not ret:
        break

    if frame_id in conf_dict:
        conf = conf_dict[frame_id]["confidence"]
        match = conf_dict[frame_id]["match_status"]
        color = (0, 255, 0) if match == 1 else (0, 0, 255)

        label = f"Conf: {conf:.2f} | Matched: {match}"

        # Add boost info if available
        if frame_id in sbiou_dict:
            row = sbiou_dict[frame_id]
            boosted = "yes" if row["boosted"] else "no"
            label += f" | Boosted: {boosted} ({row['score_before']:.2f}→{row['score_after']:.2f})"

        # Get or extrapolate bbox
        if frame_id in bbox_dict:
            box = bbox_dict[frame_id]
            x1, y1, x2, y2 = int(box["x1"]), int(box["y1"]), int(box["x2"]), int(box["y2"])
        else:
            # Use last known bbox as fallback (optional)
            prev_frames = [f for f in bbox_dict if f < frame_id]
            if prev_frames:
                last_frame = max(prev_frames)
                box = bbox_dict[last_frame]
                x1, y1, x2, y2 = int(box["x1"]), int(box["y1"]), int(box["x2"]), int(box["y2"])
                label += " (occluded)"
            else:
                x1, y1, x2, y2 = 50, 50, 150, 150  # dummy box
                label = "No bbox available"

        # Draw
        cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
        cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

    out_path = os.path.join(out_dir, f"frame_{frame_id:03}.jpg")
    cv2.imwrite(out_path, frame)
    frame_id += 1

cap.release()
print(f"✅ Annotated frames saved to {out_dir}")

!ffmpeg -framerate 10 -i  /content/track12_annotated/frame_%03d.jpg -c:v libx264 -pix_fmt yuv420p track12_video.mp4

from google.colab import files
files.download("/content/BoostTrack/output_logged_video.mp4")

#import pandas as pd
#import matplotlib.pyplot as plt
#import seaborn as sns
#import numpy as np

# Load CSVs
#confidence_df = pd.read_csv("/content/BoostTrack/confidence_log.csv")
#occlusion_df = pd.read_csv("/content/BoostTrack/occlusion_log.csv")
sbiou_df = pd.read_csv("/content/BoostTrack/sbiou_log.csv")

sns.set(style="whitegrid", font_scale=1.2)

# === 1. Confidence Evolution (Matched vs Unmatched) ===
#plt.figure(figsize=(14, 6))
#for track_id, group in confidence_df.groupby("track_id"):
    matched = group["match_status"] == 1
    plt.plot(group["frame"][matched], group["confidence"][matched], '-o', label=f"Track {track_id} (matched)", alpha=0.6)
    plt.plot(group["frame"][~matched], group["confidence"][~matched], '--x', label=f"Track {track_id} (unmatched)", alpha=0.6)
plt.xlabel("Frame")
plt.ylabel("Confidence")
plt.title("Confidence Evolution of Tracklets (Matched vs Unmatched)")
plt.legend(loc='upper right', bbox_to_anchor=(1.15, 1))
plt.tight_layout()
plt.show()

# === 2. Occlusion Confidence Decay ===
plt.figure(figsize=(10, 5))
for track_id, group in occlusion_df.groupby("track_id"):
    plt.plot(group["frame"], group["confidence"], '--', label=f"Track {track_id}")
plt.xlabel("Frame")
plt.ylabel("Confidence")
plt.title("Confidence During Occlusion Periods")
plt.legend()
plt.tight_layout()
plt.show()

# === 3. SBIoU Boosting Impact ===
plt.figure(figsize=(10, 6))
boosted = sbiou_df["boosted"] == 1
plt.scatter(sbiou_df["score_before"][boosted], sbiou_df["score_after"][boosted], c='green', label="Boosted", alpha=0.6)
plt.scatter(sbiou_df["score_before"][~boosted], sbiou_df["score_after"][~boosted], c='red', label="Not Boosted", alpha=0.4)
plt.plot([0, 1], [0, 1], 'k--', label="No Change")
plt.xlabel("Score Before Boost")
plt.ylabel("Score After Boost")
plt.title("SBIoU Boost Impact on Detection Confidence")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

# === 4. SBIoU Similarity Score Distribution ===
plt.figure(figsize=(10, 5))
sns.histplot(sbiou_df["sbiou_max"], bins=30, kde=False, color='skyblue')
plt.axvline(0.5, color='red', linestyle='--', label="< 0.5 → No Boost")
plt.axvline(0.8, color='orange', linestyle='--', label="0.5–0.8 → Conditional Boost")
plt.axvline(0.95, color='green', linestyle='--', label="> 0.8 → High Boost")
plt.xlabel("Max SBIoU Score")
plt.ylabel("Detections Count")
plt.title("Distribution of SBIoU Scores for Boost Decisions")
plt.legend()
plt.tight_layout()
plt.show()

# === 5. Heatmap: Confidence Per Track Per Frame ===
plt.figure(figsize=(14, 6))
pivot = confidence_df.pivot_table(index="track_id", columns="frame", values="confidence", aggfunc="mean")

sns.heatmap(pivot, cmap="YlGnBu", cbar_kws={'label': 'Confidence'}, linewidths=0.1, linecolor='gray')
plt.title("Tracklet Confidence Across Frames")
plt.xlabel("Frame")
plt.ylabel("Track ID")
plt.tight_layout()
plt.show()

!python /content/BoostTrack/run_boosttrack.py \
--video_path /content/BoostTrack/my_video.mp4 \
--exp_file /content/BoostTrack/external/YOLOX/exps/example/custom/yolox_s.py \
--ckpt_path /content/BoostTrack/external/YOLOX/YOLOX_outputs/yolox_s/best_ckpt.pth

!head /content/BoostTrack/confidence_log.csv

import pandas as pd

logfile = "/content/BoostTrack/YOLOX_outputs/yolox_s/vis_res/confidence_log.csv"
df = pd.read_csv(logfile, header=None)
print(df.head())
print(f"CSV shape: {df.shape}")

import pandas as pd
import matplotlib.pyplot as plt

logfile = "/content/BoostTrack/confidence_log.csv"
# Remove header=None so pandas automatically detects and uses the header row
df = pd.read_csv(logfile)

# The column names are now read from the header, so we don't need to reassign them
df.columns = ["frame", "track_id", "confidence", "time_since_update", "match_status"]

#plt.figure(figsize=(12, 6))
#for tid in df["track_id"].unique():
    # Now tid will be numeric track IDs, so conversion to int is safe
    if tid == -1:
        continue
    track_data = df[df["track_id"] == tid]
    plt.plot(track_data["frame"], track_data["confidence"], label=f"Track {int(tid)}")

plt.xlabel("Frame")
plt.ylabel("Tracklet Confidence")
plt.title("Tracklet Confidence Over Time")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.savefig("/content/BoostTrack/tracklet_confidence_graph.png")
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

df = pd.read_csv("/content/BoostTrack/confidence_log.csv")

plt.figure(figsize=(12, 6))
for track_id in df['TrackID'].unique():
    track_data = df[df['TrackID'] == track_id]
    plt.plot(track_data['Frame'], track_data['Confidence'], label=f'Track {track_id}')
plt.xlabel("Frame")
plt.ylabel("Confidence Score")
plt.title("Tracklet Confidence Over Time")
plt.legend()
plt.grid(True)
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
# No need for seaborn for the plots we can currently generate

#logfile = "/content/BoostTrack/confidence_log.csv"

# Read the CSV, assuming it has a header with the correct names
# based on the !head command output, it seems to have 'frame', 'track_id', 'confidence'
# If the header is missing, you would need header=None and assign columns manually
try:
    df = pd.read_csv(logfile)
except Exception as e:
    print(f"Error reading CSV with header: {e}")
    print("Attempting to read without header and assign columns...")
    # Fallback if read_csv with header fails
    try:
        df = pd.read_csv(logfile, header=None)
        # Assign column names based on the observed structure
        if df.shape[1] >= 3: # Check if there are at least 3 columns
             df.columns = ["frame", "track_id", "confidence"] + [f"col{i}" for i in range(3, df.shape[1])]
        else:
             print("CSV does not have the expected number of columns.")
             # You might want to handle this case further, perhaps raise an error or skip plotting
             raise ValueError("CSV does not have enough columns.")
    except Exception as e_fallback:
         print(f"Error reading CSV without header: {e_fallback}")
         print("Could not read the CSV file in either mode.")
         # Exit the script or function if CSV cannot be read
         raise e_fallback


# Ensure 'track_id' and 'frame' are numeric for plotting
# Handle potential non-numeric values gracefully
try:
    df['track_id'] = pd.to_numeric(df['track_id'], errors='coerce')
    df['frame'] = pd.to_numeric(df['frame'], errors='coerce')
    df['confidence'] = pd.to_numeric(df['confidence'], errors='coerce')
    # Drop rows where critical columns could not be converted
    df.dropna(subset=['track_id', 'frame', 'confidence'], inplace=True)
except Exception as e:
    print(f"Error converting columns to numeric: {e}")
    # Handle the error, perhaps log it and exit
    raise e

# --- Plotting Tracklet Confidence Over Time ---
plt.figure(figsize=(12, 6))

# Iterate through unique track_ids, ignoring potential -1 or NaN
#for tid in df["track_id"].dropna().unique():
    # tid is now guaranteed to be numeric by dropna()
    track_data = df[df["track_id"] == tid]
    # Ensure track_data is not empty before plotting
    if not track_data.empty:
        # Plot 'confidence' as it's the available confidence column
        plt.plot(track_data["frame"], track_data["confidence"], label=f"Track {int(tid)}")

plt.xlabel("Frame")
plt.ylabel("Tracklet Confidence") # Adjusted label
plt.title("Tracklet Confidence Over Time (Based on available data)") # Adjusted title
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.savefig("/content/BoostTrack/tracklet_confidence_graph.png")
plt.show()
plt.clf() # Clear the current figure

# The other plots (detection boosting, SBIoU, occlusion drop)
# require columns that are not present in the current CSV.
# You will need to modify the data generation process (BoostTrack script)
# to include these columns if you want to generate those plots.
print("Additional plots (detection boosting, SBIoU, occlusion) cannot be generated")
print("as required columns are not present in confidence_log.csv.")

"""CALCULATING PERFORMANCE METRICS"""

!pip install motmetrics

import pandas as pd

# Load tracker output
bbox_df = pd.read_csv("/content/BoostTrack/bbox_log.csv")

# Convert (x1, y1, x2, y2) → (x, y, w, h)
bbox_df["w"] = bbox_df["x2"] - bbox_df["x1"]
bbox_df["h"] = bbox_df["y2"] - bbox_df["y1"]

# MOT format: frame, id, x, y, w, h, conf, class, visibility
bbox_df["class"] = 1      # assuming 'person' class
bbox_df["vis"] = 1.0      # assuming full visibility
bbox_df["conf"] = bbox_df["confidence"]

# Keep only necessary columns in correct order
mot_pred = bbox_df[["frame", "track_id", "x1", "y1", "w", "h", "conf", "class", "vis"]]
mot_pred.to_csv("/content/track_output.txt", index=False, header=False)
print("✅ Saved MOT-format tracker predictions to /content/track_output.txt")

import motmetrics as mm

# Load ground truth and prediction
gt = mm.io.loadtxt("/content/ground_truth.txt", fmt="mot16-2D", min_confidence=0.0)
ts = mm.io.loadtxt("/content/track_output.txt", fmt="mot16-2D", min_confidence=0.0)

# Compare using IoU distance with 0.5 threshold
acc = mm.utils.compare_to_groundtruth(gt, ts, 'iou', distth=0.5)

# Compute metrics
mh = mm.metrics.create()
summary = mh.compute(acc, metrics=['mota', 'motp', 'idf1', 'precision', 'recall', 'num_switches'], name='BoostTrack++')

# Show table
print(summary)

# Restart runtime after running this cell
!pip install numpy==1.23.5 motmetrics --force-reinstall

import motmetrics as mm

# Load ground truth and prediction
gt = mm.io.loadtxt("/content/ground_truth.txt", fmt="mot16-2D", min_confidence=0.0)
ts = mm.io.loadtxt("/content/track_output.txt", fmt="mot16-2D", min_confidence=0.0)

# Evaluate
acc = mm.utils.compare_to_groundtruth(gt, ts, 'iou', distth=0.5)
mh = mm.metrics.create()
summary = mh.compute(acc, metrics=['mota', 'motp', 'idf1', 'precision', 'recall', 'num_switches'], name='BoostTrack++')
print(summary)

# Example for MOT20-01
bbox_csv = "/content/BoostTrack/bbox_log.csv"  # generated during tracking
output_txt = "/content/BoostTrack/preds/MOT20-01.txt"

df = pd.read_csv(bbox_csv)
df = df[df["track_id"] > 0]  # exclude -1 or dummy IDs
df['x'] = df['x1']
df['y'] = df['y1']
df['w'] = df['x2'] - df['x1']
df['h'] = df['y2'] - df['y1']
df_mot = df[['frame', 'track_id', 'x', 'y', 'w', 'h', 'confidence']]
df_mot['class'] = -1
df_mot['visibility'] = -1
df_mot.to_csv(output_txt, header=False, index=False)

import os
os.makedirs("/content/BoostTrack/preds", exist_ok=True)

!pip install -U motmetrics

import pandas as pd

# Path to your bbox log and where to write prediction files
bbox_log_path = "/content/BoostTrack/bbox_log.csv"
output_dir = "/content/BoostTrack/preds"
os.makedirs(output_dir, exist_ok=True)

# Load full bbox log
df = pd.read_csv(bbox_log_path)

# Group by sequence name if you have video_name or sequence info
# If your log doesn't include that, this assumes you process one sequence at a time
# Otherwise, you need to have a column like "seq_name" for proper grouping
sequences = df["video_name"].unique() if "video_name" in df.columns else ["default"]

if "video_name" not in df.columns:
    df["video_name"] = "MOT20-01"  # or whichever sequence you're working on

# Create .txt for each sequence
for seq in df["video_name"].unique():
    seq_df = df[df["video_name"] == seq].copy()

    # Convert (x1, y1, x2, y2) to (x, y, w, h)
    seq_df["x"] = seq_df["x1"]
    seq_df["y"] = seq_df["y1"]
    seq_df["w"] = seq_df["x2"] - seq_df["x1"]
    seq_df["h"] = seq_df["y2"] - seq_df["y1"]

    # Reorder and fill MOTChallenge required format
    mot_format = seq_df[["frame", "track_id", "x", "y", "w", "h", "confidence"]].copy()
    mot_format["class"] = -1
    mot_format["vis"] = -1
    mot_format["unused"] = -1

    # Save
    pred_path = os.path.join(output_dir, f"{seq}.txt")
    mot_format.to_csv(pred_path, header=False, index=False)
    print(f"✅ Saved prediction for {seq} to {pred_path}")

import pandas as pd

df = pd.read_csv("/content/BoostTrack/preds/default_sequence.txt", header=None)
df.columns = ["frame", "id", "x", "y", "w", "h", "conf", "class", "vis", "extra"][:df.shape[1]]  # handles 9 or 10 columns

# Drop duplicates based on (frame, id)
df = df.drop_duplicates(subset=["frame", "id"])

# Save cleaned prediction
df.to_csv("/content/BoostTrack/preds/MOT20-01.txt", header=False, index=False)
print("✅ Cleaned prediction file saved.")

import motmetrics as mm
import pandas as pd
import os
from glob import glob

# === CONFIG ===
gt_base = "/content/drive/MyDrive/BoostTrack/data"
pred_base = "/content/BoostTrack/preds"

# === Find all gt.txt files ===
gt_files = glob(f"{gt_base}/MOT*/train/*/gt/gt.txt")
print(f"Found {len(gt_files)} GT sequences")

accs = []
names = []

for gt_file in gt_files:
    # Correctly extract sequence name like 'MOT20-01'
    seq_name = os.path.basename(os.path.dirname(os.path.dirname(gt_file)))

    pred_file = os.path.join(pred_base, f"{seq_name}.txt")

    if not os.path.exists(pred_file):
        print(f"❌ Skipping {seq_name} — prediction not found at {pred_file}")
        continue

    print(f"✅ Evaluating {seq_name}")
    gt = mm.io.loadtxt(gt_file, min_confidence=0.0)
    ts = mm.io.loadtxt(pred_file, min_confidence=0.0)
    acc = mm.utils.compare_to_groundtruth(gt, ts, 'iou', 0.5)


    accs.append(acc)
    names.append(seq_name)

# === Compute summary ===
mh = mm.metrics.create()
summary = mh.compute_many(
    accs,
    names=names,
    metrics=mm.metrics.motchallenge_metrics,
    generate_overall=True
)

# === Save and display ===
summary_csv = "/content/BoostTrack/mot_eval_summary.csv"
summary.to_csv(summary_csv)
print(f"\n✅ Evaluation complete. Summary saved to: {summary_csv}")
print(summary)

import motmetrics as mm
import os

# === File paths ===
gt_file = "/content/drive/MyDrive/BoostTrack/data/MOT20/train/MOT20-01/gt/gt.txt"
pred_file = "/content/BoostTrack/preds/default_sequence.txt"

# === Load ground truth and predictions ===
gt = mm.io.loadtxt(gt_file, fmt="mot15-2D", min_confidence=1)
ts = mm.io.loadtxt(pred_file, fmt="mot15-2D", min_confidence=0.0)

# === Compare using IOU with threshold 0.5 ===
acc = mm.utils.compare_to_groundtruth(gt, ts, dist='iou', distth=0.5)

# === Compute metrics ===
mh = mm.metrics.create()
summary = mh.compute(acc, metrics=mm.metrics.motchallenge_metrics, name="MOT20-01")

# === Render summary ===
print(mm.io.render_summary(summary, formatters=mh.formatters))

import pandas as pd
import os

# === CONFIG ===
bbox_csv = "/content/BoostTrack/bbox_log.csv"
output_txt = "/content/BoostTrack/preds/MOT20-01.txt"
os.makedirs(os.path.dirname(output_txt), exist_ok=True)

# Load your bbox CSV
df = pd.read_csv(bbox_csv)

# Format for MOT: frame, id, x, y, w, h, score, -1, -1, -1
with open(output_txt, "w") as f:
    for _, row in df.iterrows():
        frame = int(row["frame"]) + 1  # Convert to 1-based indexing
        track_id = int(row["track_id"])
        x1, y1, x2, y2 = row["x1"], row["y1"], row["x2"], row["y2"]
        conf = float(row["confidence"])

        # Convert (x1, y1, x2, y2) -> (x, y, w, h)
        x = x1
        y = y1
        w = x2 - x1
        h = y2 - y1

        # Skip low-confidence detections if needed
        if conf < 0.2:
            continue

        line = f"{frame},{track_id},{x:.2f},{y:.2f},{w:.2f},{h:.2f},{conf:.4f},-1,-1,-1\n"
        f.write(line)

import pandas as pd

# Load original bbox log
df = pd.read_csv("/content/BoostTrack/bbox_log.csv")

# Convert to MOT format
df["w"] = df["x2"] - df["x1"]
df["h"] = df["y2"] - df["y1"]

mot_df = df[["frame", "track_id", "x1", "y1", "w", "h", "confidence"]].copy()
mot_df["class"] = -1
mot_df["vis"] = -1
mot_df["dummy"] = -1

# Save to MOT format file
mot_df.to_csv("/content/BoostTrack/preds/default_sequence.txt", index=False, header=False)

import pandas as pd
import os

# Load your tracking log
bbox_log = pd.read_csv('/content/bbox_log_seq.csv')  # must contain: seq, frame, id, x, y, w, h, conf

# Create output folder
os.makedirs('preds', exist_ok=True)

# Group by sequence (e.g., MOT20-01, MOT20-02)
if 'seq' not in bbox_log.columns:
    print("Missing 'seq' column in bbox_log.csv. Please add it to associate rows with sequences.")
else:
    for seq_name, group in bbox_log.groupby('seq'):
        output_file = os.path.join('preds', f'{seq_name}.txt')

        with open(output_file, 'w') as f:
            for _, row in group.iterrows():
                line = f"{int(row['frame'])},{int(row['id'])},{row['x']:.2f},{row['y']:.2f},{row['w']:.2f},{row['h']:.2f},{row['conf']:.2f},-1,-1,-1\n"
                f.write(line)

        print(f"[✓] Wrote: {output_file}")

import pandas as pd

df = pd.read_csv('/content/BoostTrack/bbox_log.csv')

# Assign fixed sequence name
df['seq'] = 'MOT20-01'  # or MOT17-02, etc.

# Rename columns to match expected format
df = df.rename(columns={
    'track_id': 'id',
    'x1': 'x',
    'y1': 'y',
    'x2': 'x2',
    'y2': 'y2',
    'confidence': 'conf'
})

# Convert x, y, w, h from x1, y1, x2, y2
df['w'] = df['x2'] - df['x']
df['h'] = df['y2'] - df['y']

# Drop extra columns
df = df[['seq', 'frame', 'id', 'x', 'y', 'w', 'h', 'conf']]

# Save updated file
df.to_csv('bbox_log_seq.csv', index=False)
print("✅ Saved: bbox_log_seq.csv with sequence info")

import motmetrics as mm
import os

gt_base = '/content/drive/MyDrive/BoostTrack/data/MOT20/train'  # or MOT17/train
pred_base = 'preds'
accs = []
names = []

for seq_name in os.listdir(gt_base):
    gt_file = os.path.join(gt_base, seq_name, 'gt', 'gt.txt')
    pred_file = os.path.join(pred_base, f'{seq_name}.txt')

    if not os.path.exists(pred_file):
        print(f"[!] Skipping {seq_name}: no prediction file found.")
        continue

    # Load GT and predictions
    gt = mm.io.loadtxt(gt_file, fmt="motchallenge-2D")
    pred = mm.io.loadtxt(pred_file, fmt="motchallenge-2D")

    # Match and compute accuracy
    acc = mm.utils.compare_to_groundtruth(gt, pred, 'iou', distth=0.5)
    accs.append(acc)
    names.append(seq_name)

mh = mm.metrics.create()
summary = mh.compute_many(
    accs,
    names=names,
    metrics=mm.metrics.motchallenge_metrics + ['HOTA'],
    generate_overall=True
)

# Print table
print(mm.io.render_summary(summary, formatters=mh.formatters, namemap=mm.io.motchallenge_metric_names))

import motmetrics as mm
import os

gt_root = '/content/BoostTrack/data/MOT20/train/'
seq = 'MOT20-01'

gt_file = os.path.join(gt_root, seq, 'gt', 'gt.txt')
pred_file = os.path.join(gt_root, 'preds', f'{seq}.txt')  # ensure this file exists

gt = mm.io.loadtxt(gt_file, fmt='motchallenge')
pred = mm.io.loadtxt(pred_file, fmt='motchallenge')

acc = mm.utils.compare_to_groundtruth(gt, pred, 'iou', distth=0.5)

mh = mm.metrics.create()
summary = mh.compute(acc, metrics=mm.metrics.motchallenge_metrics, name=seq)

print(mm.io.render_summary(summary, formatters=mh.formatters, namemap=mh.names))

import pandas as pd

df = pd.read_csv("/content/BoostTrack/preds/MOT20-01.txt", header=None)
df.columns = ["frame", "id", "x", "y", "w", "h", "conf", "class", "vis", "extra"][:df.shape[1]]  # handles 9 or 10 columns

# Drop duplicates based on (frame, id)
df = df.drop_duplicates(subset=["frame", "id"])

# Save cleaned prediction
df.to_csv("/content/BoostTrack/preds/MOT20-01.txt", header=False, index=False)
print("✅ Cleaned prediction file saved.")

import pandas as pd
import motmetrics as mm
import motmetrics.metrics as mm_metrics


def load_mot_data(filename, is_gt=True):
    # Define columns to match your file format
    columns = ['frame', 'id', 'bb_left', 'bb_top', 'bb_width', 'bb_height', 'conf', 'x', 'y']
    df = pd.read_csv(filename, header=None, names=columns)

    # For GT, keep all rows, for predictions, optionally filter by confidence threshold if needed
    if not is_gt:
        df = df[df['conf'] > 0.1]  # Example: filter low-confidence preds

    # Group detections by frame
    grouped = df.groupby('frame')

    data = {}
    for frame, group in grouped:
        # For each frame, create dict: id -> (tlwh)
        frame_data = {}
        for _, row in group.iterrows():
            tlwh = [row['bb_left'], row['bb_top'], row['bb_width'], row['bb_height']]
            frame_data[int(row['id'])] = tlwh
        data[frame] = frame_data

    return data

# Paths to your files
gt_file = '/content/BoostTrack/data/MOT20/train/MOT20-01/gt/gt.txt'          # Replace with your actual path
pred_file = '/content/BoostTrack/preds/MOT20-01.txt'  # Replace with your actual path

# Load data
gt_data = load_mot_data(gt_file, is_gt=True)
pred_data = load_mot_data(pred_file, is_gt=False)

# Create MOTAccumulator and update frame by frame
acc = mm.MOTAccumulator(auto_id=True)

for frame in sorted(gt_data.keys()):
    gt_ids = list(gt_data[frame].keys())
    gt_boxes = list(gt_data[frame].values())

    pred_ids = list(pred_data.get(frame, {}).keys())
    pred_boxes = list(pred_data.get(frame, {}).values())

    # Compute IoU distance matrix between GT and predictions
    dists = mm.distances.iou_matrix(gt_boxes, pred_boxes, max_iou=0.5)

    # Update accumulator with this frame's data
    acc.update(gt_ids, pred_ids, dists)

# Calculate metrics summary
mh = mm.metrics.create()
summary = mh.compute(acc, metrics=mm.metrics.motchallenge_metrics, name='MOT20-01')
summary = summary.rename_axis('metric').transpose()

def safe_percent(x):
    try:
        if x is None or (isinstance(x, float) and (x != x)):  # NaN
            return "N/A"
        return f"{x:.1%}"
    except Exception:
        return "N/A"

def safe_float(x):
    try:
        if x is None or (isinstance(x, float) and (x != x)):
            return "N/A"
        return f"{x:.3f}"
    except Exception:
        return "N/A"

def safe_int(x):
    try:
        if x is None or (isinstance(x, float) and (x != x)):
            return "N/A"
        return f"{int(x)}"
    except Exception:
        return "N/A"


formatters = {
    'idf1': safe_percent,
    'idp': safe_percent,
    'idr': safe_percent,
    'recall': safe_percent,
    'precision': safe_percent,
    'mota': safe_percent,
    'motp': safe_float,
    'num_unique_objects': safe_int,
    'mostly_tracked': safe_int,
    'partially_tracked': safe_int,
    'mostly_lost': safe_int,
    'num_false_positives': safe_int,
    'num_misses': safe_int,
    'num_switches': safe_int,
    'num_fragmentations': safe_int,
    'num_transfer': safe_int,
    'num_ascend': safe_int,
    'num_migrate': safe_int,
}
namemap = {
    'idf1': 'IDF1',
    'idp': 'ID Precision',
    'idr': 'ID Recall',
    'recall': 'Recall',
    'precision': 'Precision',
    'mota': 'MOTA',
    'num_unique_objects': 'GT Objects',
    'mostly_tracked': 'Mostly Tracked',
    'partially_tracked': 'Partially Tracked',
    'mostly_lost': 'Mostly Lost',
    'num_false_positives': 'False Positives',
    'num_misses': 'Misses',
    'num_switches': 'ID Switches',
    'num_fragmentations': 'Fragmentations',
    'num_transfer': 'Transfers',
    'num_ascend': 'Ascends',
    'num_migrate': 'Migrations',
}
print(mm.io.render_summary(summary, formatters=formatters, namemap=namemap))

#print(summary)
#print(summary.shape)

import pandas as pd
import os

# Load the tracking log
log_file = '/content/bbox_log_seq.csv'
required_cols = ['seq', 'frame', 'id', 'x', 'y', 'w', 'h', 'conf']

# Check file exists
if not os.path.exists(log_file):
    raise FileNotFoundError(f"Tracking log file not found: {log_file}")

bbox_log = pd.read_csv(log_file)

# Ensure required columns exist
missing_cols = [col for col in required_cols if col not in bbox_log.columns]
if missing_cols:
    raise ValueError(f"Missing required columns in log file: {missing_cols}")

# Create output directory
os.makedirs('preds', exist_ok=True)

# Group by sequence and write separate prediction files
for seq_name, group in bbox_log.groupby('seq'):
    output_file = os.path.join('preds', f'{seq_name}.txt')

    with open(output_file, 'w') as f:
        for _, row in group.iterrows():
            line = f"{int(row['frame'])},{int(row['id'])},{row['x']:.2f},{row['y']:.2f},{row['w']:.2f},{row['h']:.2f},{row['conf']:.2f},-1,-1,-1\n"
            f.write(line)

    print(f"[✓] Wrote predictions for {seq_name} → {output_file}")

import pandas as pd

df = pd.read_csv('/content/BoostTrack/tracking_results/merged_tracking.csv')
print(df['sequence'].unique())

import pandas as pd
import os
from glob import glob

# === CONFIG ===
gt_base = "/content/drive/MyDrive/BoostTrack/data"
log_folder = "/content/BoostTrack/data"  # Where your bbox_log_MOT20-*.csv files are
merged_output = "/content/BoostTrack/bbox_log_seq.csv"

# === Find all GT files to get sequence names ===
gt_files = glob(f"{gt_base}/MOT*/train/*/gt/gt.txt")
print(f"Found {len(gt_files)} GT sequences")

# === Collect logs ===
all_logs = []

for gt_file in gt_files:
    seq_name = os.path.basename(os.path.dirname(os.path.dirname(gt_file)))  # e.g. MOT20-01
    log_file = os.path.join(log_folder, f"bbox_log_{seq_name}.csv")

    if not os.path.exists(log_file):
        print(f"❌ Skipping {seq_name} — log not found at {log_file}")
        continue

    df = pd.read_csv(log_file)
    df['seq'] = seq_name  # Add sequence name column
    all_logs.append(df)
    print(f"✅ Loaded {seq_name} log with {len(df)} rows")

# === Merge and save ===
if all_logs:
    merged_df = pd.concat(all_logs, ignore_index=True)
    merged_df.to_csv(merged_output, index=False)
    print(f"\n✅ Merged all logs into: {merged_output} ({len(merged_df)} total rows)")
else:
    print("⚠️ No logs were found. Please check paths or generate the log files first.")

import pandas as pd
import os

# List of GT file paths you provided (add or remove as needed)
gt_paths = [
    "/content/BoostTrack/data/MOT17/train/MOT17-13-SDP/gt/gt_train_half.txt",
    "/content/BoostTrack/data/MOT17/train/MOT17-13-FRCNN/gt/gt.txt",
    "/content/BoostTrack/data/MOT17/train/MOT17-13-DPM/gt/gt_val_half.txt",
    "/content/BoostTrack/data/MOT17/train/MOT17-11-SDP/gt/gt.txt",
    "/content/BoostTrack/data/MOT17/train/MOT17-11-FRCNN/gt/gt.txt",
    "/content/BoostTrack/data/MOT17/train/MOT17-11-DPM/gt/gt.txt",
    "/content/BoostTrack/data/MOT17/train/MOT17-10-SDP/gt/gt.txt",
    "/content/BoostTrack/data/MOT17/train/MOT17-10-FRCNN/gt/gt_train_half.txt",
    "/content/BoostTrack/data/MOT17/train/MOT17-10-DPM/gt/gt_train_half.txt",
    "/content/BoostTrack/data/MOT17/train/MOT17-09-SDP/gt/gt.txt",
    "/content/BoostTrack/data/MOT17/train/MOT17-09-FRCNN/gt/gt.txt",
    "/content/BoostTrack/data/MOT17/train/MOT17-09-DPM/gt/gt.txt",
    "/content/BoostTrack/data/MOT17/train/MOT17-05-FRCNN/gt/gt.txt",
    "/content/BoostTrack/data/MOT17/train/MOT17-05-DPM/gt/gt.txt",
    "/content/BoostTrack/data/MOT17/train/MOT17-04-SDP/gt/gt_train_half.txt",
    "/content/BoostTrack/data/MOT17/train/MOT17-04-FRCNN/gt/gt.txt",
    # Skipping MOT17-04-DPM (no gt file path provided)
    "/content/BoostTrack/data/MOT17/train/MOT17-02-SDP/gt/gt_train_half.txt",
    # Skipping MOT17-02-FRCNN and MOT17-02-DPM (no gt file path provided)
    "/content/BoostTrack/data/MOT20/train/MOT20-01/gt/gt.txt",
    "/content/BoostTrack/data/MOT20/train/MOT20-02/gt/gt.txt",
    "/content/BoostTrack/data/MOT20/train/MOT20-03/gt/gt.txt",
    "/content/BoostTrack/data/MOT20/train/MOT20-05/gt/gt.txt",
]

log_folder = "/content/BoostTrack/logs"  # Your folder containing bbox_log_*.csv
merged_output = "/content/BoostTrack/bbox_log_seq.csv"

all_logs = []

for gt_file in gt_paths:
    if not os.path.exists(gt_file):
        print(f"❌ GT file does not exist: {gt_file}")
        continue

    # Correct extraction of sequence name:
    seq_name = os.path.basename(os.path.dirname(os.path.dirname(gt_file)))

    log_file = os.path.join(log_folder, f"bbox_log_{seq_name}.csv")
    if not os.path.exists(log_file):
        print(f"❌ Log file missing for {seq_name}: {log_file}")
        continue

    df = pd.read_csv(log_file)
    df['seq'] = seq_name
    all_logs.append(df)
    print(f"✅ Added logs for {seq_name}, {len(df)} rows")

if all_logs:
    merged_df = pd.concat(all_logs, ignore_index=True)
    merged_df.to_csv(merged_output, index=False)
    print(f"\n✅ Merged all logs into: {merged_output} ({len(merged_df)} rows total)")
else:
    print("⚠️ No logs merged. Check your GT and log file paths.")

import pandas as pd
import os

# Load your full bbox_log dataframe with a 'seq' column for sequence names
bbox_log = pd.read_csv('/content/bbox_log_seq.csv')  # This file should have seq, frame, id, x, y, w, h, conf columns

# Output folder for individual sequence CSV logs
output_dir = '/content/BoostTrack/logs'
os.makedirs(output_dir, exist_ok=True)

# Group by sequence and write each to a separate CSV
for seq_name, group in bbox_log.groupby('seq'):
    seq_file = os.path.join(output_dir, f'bbox_log_{seq_name}.csv')
    group.to_csv(seq_file, index=False)
    print(f"[✓] Written bbox log for {seq_name}: {seq_file}")

import pandas as pd
import os

# Example: Your combined bbox_log with predictions for all sequences
# This CSV must have 'seq' column to indicate which sequence each prediction belongs to
bbox_log = pd.read_csv('/content/bbox_log_seq.csv')  # Make sure this file has all sequences with 'seq'

# Output directory
output_dir = '/content/BoostTrack/preds'
os.makedirs(output_dir, exist_ok=True)

# Check unique sequences present in your bbox_log
print("Sequences found in bbox_log:", bbox_log['seq'].unique())

# Group by sequence and write prediction file for each sequence
for seq_name, group in bbox_log.groupby('seq'):
    pred_file = os.path.join(output_dir, f'{seq_name}.txt')
    with open(pred_file, 'w') as f:
        for _, row in group.iterrows():
            # Write line in MOTChallenge format
            line = f"{int(row['frame'])},{int(row['id'])},{row['x']:.2f},{row['y']:.2f},{row['w']:.2f},{row['h']:.2f},{row['conf']:.2f},-1,-1,-1\n"
            f.write(line)
    print(f"[✓] Written prediction for {seq_name} → {pred_file}")

import os
from glob import glob

# Base folder where your sequences are stored
base_folder = "/content/BoostTrack/data"

# Where to save your tracking outputs (prediction CSVs)
output_folder = "/content/BoostTrack/tracking_results"
os.makedirs(output_folder, exist_ok=True)

# Get all sequence folders recursively (modify this glob pattern if needed)
sequence_paths = glob(os.path.join(base_folder, "MOT*/train/*"))

print(f"Found {len(sequence_paths)} sequences")

def run_tracker_on_sequence(seq_path, output_csv):
    """
    Replace this with your actual tracker running code on a single sequence.
    It should save a CSV file at output_csv containing tracking results with columns:
    frame, id, x, y, w, h, conf
    """
    print(f"Running tracker on {seq_path}")

    # Example: If you have a command line tracker script, you can run subprocess here
    # import subprocess
    # cmd = f"python your_tracker_script.py --input {seq_path} --output {output_csv}"
    # subprocess.run(cmd, shell=True)

    # Or if you have a python function to call, call it here:
    # tracker.run(seq_path, output_csv)

    # For now, just simulate output for demo:
    with open(output_csv, "w") as f:
        f.write("frame,id,x,y,w,h,conf\n")
        f.write("1,1,100,100,50,50,0.9\n")  # Dummy example line

# Run tracking on each sequence and save CSV
for seq_path in sequence_paths:
    seq_name = os.path.basename(seq_path)
    output_csv_path = os.path.join(output_folder, f"{seq_name}.csv")
    run_tracker_on_sequence(seq_path, output_csv_path)
    print(f"[✓] Saved tracking result: {output_csv_path}")

print("All sequences processed.")

import pandas as pd
import glob
import os

tracking_folder = "/content/BoostTrack/tracking_results"
merged_file = "/content/BoostTrack/tracking_results/merged_tracking.csv"

all_files = glob.glob(os.path.join(tracking_folder, "*.csv"))

df_list = []
for file in all_files:
    df = pd.read_csv(file)
    # Optional: add a column for sequence name
    seq_name = os.path.splitext(os.path.basename(file))[0]
    df['sequence'] = seq_name
    df_list.append(df)

merged_df = pd.concat(df_list, ignore_index=True)
merged_df.to_csv(merged_file, index=False)

print(f"[✓] Merged all tracking CSVs into {merged_file}")

import motmetrics as mm
import pandas as pd

# Load merged tracking results
merged_df = pd.read_csv('/content/BoostTrack/tracking_results/merged_tracking.csv')

# Base GT folders
gt_folder_mot17 = '/content/BoostTrack/data/MOT17/train'
gt_folder_mot20 = '/content/BoostTrack/data/MOT20/train'

# Get unique sequences
sequences = merged_df['sequence'].unique()

# Helper: get GT path
def get_gt_path(seq):
    if seq.startswith('MOT20'):
        return f"{gt_folder_mot20}/{seq}/gt/gt.txt"
    elif seq.startswith('MOT17'):
        return f"{gt_folder_mot17}/{seq}/gt/gt.txt"
    else:
        raise ValueError(f"Unknown sequence prefix for sequence {seq}")

# Init accumulators
accumulators = {}

for seq in sequences:
    print(f"Evaluating sequence {seq}...")
    try:
        # Load GT
        gt_path = get_gt_path(seq)
        gt = pd.read_csv(gt_path, header=None)
        gt.columns = ['frame', 'id', 'bb_left', 'bb_top', 'bb_width', 'bb_height', 'conf', 'class', 'visibility']
        gt = gt[gt['conf'] == 1]

        # Load tracker results
        trk = merged_df[merged_df['sequence'] == seq]

        # Create accumulator
        acc = mm.MOTAccumulator(auto_id=True)

        frames = sorted(gt['frame'].unique())
        for frame in frames:
            gt_frame = gt[gt['frame'] == frame]
            trk_frame = trk[trk['frame'] == frame]

            gt_ids = gt_frame['id'].values
            gt_boxes = gt_frame[['bb_left', 'bb_top', 'bb_width', 'bb_height']].values

            trk_ids = trk_frame['id'].values
            trk_boxes = trk_frame[['x', 'y', 'w', 'h']].values

            distances = mm.distances.iou_matrix(gt_boxes, trk_boxes, max_iou=0.5)
            acc.update(gt_ids, trk_ids, distances)

        # Only add to dict if processing was successful
        accumulators[seq] = acc

    except Exception as e:
        print(f"Error processing sequence {seq}: {e}")

# Filter out bad entries and compute summary
if accumulators:
    mh = mm.metrics.create()
    metrics = ['idf1', 'idp', 'idr', 'mota', 'num_switches']  # Removed 'motap'

    summary = mh.compute_many(
      list(accumulators.values()),
      names=list(accumulators.keys()),
      metrics=metrics,
      generate_overall=True
)

    print(mm.io.render_summary(
      summary,
      formatters=mh.formatters,
      namemap=mm.io.motchallenge_metric_names
))
else:
    print("No valid sequences found for evaluation.")

import os
import shutil
from glob import glob

# Base path
src_base = "/content/BoostTrack/results/gt/MOT17-val"
dst_base = "/content/BoostTrack/results"

# Find all gt.txt files
gt_files = glob(os.path.join(src_base, "*", "gt", "gt.txt"))

for gt_path in gt_files:
    # Extract sequence name, e.g., MOT17-02-FRCNN
    seq_name = gt_path.split("/")[-3]

    # Define new destination path
    dst_path = os.path.join(dst_base, f"{seq_name}.txt")

    # Move and rename
    shutil.move(gt_path, dst_path)
    print(f"Moved: {gt_path} → {dst_path}")

import os
import shutil
from glob import glob

# Base path
src_base = "/content/BoostTrack/results/gt/MOT20-val"
dst_base = "/content/BoostTrack/results"

# Find all gt.txt files
gt_files = glob(os.path.join(src_base, "*", "gt", "gt.txt"))

for gt_path in gt_files:
    # Extract sequence name, e.g., MOT17-02-FRCNN
    seq_name = gt_path.split("/")[-3]

    # Define new destination path
    dst_path = os.path.join(dst_base, f"{seq_name}.txt")

    # Move and rename
    shutil.move(gt_path, dst_path)
    print(f"Moved: {gt_path} → {dst_path}")

import os

results_dir = "/content/BoostTrack/results"

for filename in os.listdir(results_dir):
    if filename.endswith(".txt"):
        path = os.path.join(results_dir, filename)
        lines_fixed = []

        with open(path, "r") as file:
            for line in file:
                fields = line.strip().split(',')
                if len(fields) >= 6:
                    # Fix confidence and drop extra fields
                    frame = fields[0]
                    track_id = fields[1]
                    x, y, w, h = fields[2:6]
                    conf = fields[6] if float(fields[6]) > 0 else "1.0"
                    lines_fixed.append(f"{frame},{track_id},{x},{y},{w},{h},{conf},-1,-1")

        # Overwrite with fixed content
        with open(path, "w") as file:
            for line in lines_fixed:
                file.write(line + "\n")

        print(f"Fixed: {filename}")

import motmetrics as mm
import pandas as pd
import numpy as np
import os

# Load tracking results
merged_df = pd.read_csv('/content/BoostTrack/tracking_results/merged_tracking.csv')

# Base GT folders
gt_folder_mot17 = '/content/BoostTrack/data/MOT17/train'
gt_folder_mot20 = '/content/BoostTrack/data/MOT20/train'

# Get unique sequences
sequences = merged_df['sequence'].unique()
accumulators = {}

def get_gt_path(seq):
    if seq.startswith('MOT20'):
        return f"{gt_folder_mot20}/{seq}/gt/gt.txt"
    elif seq.startswith('MOT17'):
        return f"{gt_folder_mot17}/{seq}/gt/gt.txt"
    else:
        raise ValueError(f"Unknown sequence prefix: {seq}")

for seq in sequences:
    print(f"Evaluating {seq}...")
    try:
        # Load GT
        gt_path = get_gt_path(seq)
        gt = pd.read_csv(gt_path, header=None)
        gt.columns = ['frame', 'id', 'bb_left', 'bb_top', 'bb_width', 'bb_height', 'conf', 'class', 'vis']
        gt = gt[gt['conf'] == 1]

        # Load tracker
        trk = merged_df[merged_df['sequence'] == seq]
        acc = mm.MOTAccumulator(auto_id=True)

        for frame_id in sorted(gt['frame'].unique()):
            gt_frame = gt[gt['frame'] == frame_id]
            trk_frame = trk[trk['frame'] == frame_id]

            # Clean up tracker boxes
            trk_frame = trk_frame.dropna(subset=['x', 'y', 'w', 'h'])
            trk_frame = trk_frame[(trk_frame['w'] > 0) & (trk_frame['h'] > 0)]

            gt_ids = gt_frame['id'].values
            gt_boxes = gt_frame[['bb_left', 'bb_top', 'bb_width', 'bb_height']].values

            trk_ids = trk_frame['id'].values
            trk_boxes = trk_frame[['x', 'y', 'w', 'h']].values

            distances = mm.distances.iou_matrix(gt_boxes, trk_boxes, max_iou=0.5)
            acc.update(gt_ids, trk_ids, distances)

        accumulators[seq] = acc

    except Exception as e:
        print(f"Error evaluating {seq}: {e}")

# Summarize
if accumulators:
    mh = mm.metrics.create()
    summary = mh.compute_many(
        list(accumulators.values()),
        names=list(accumulators.keys()),
        metrics=['idf1', 'idp', 'idr', 'mota', 'num_switches'],
        generate_overall=True
    )

    print(mm.io.render_summary(summary, formatters=mh.formatters, namemap=mm.io.motchallenge_metric_names))
else:
    print("No valid sequences evaluated.")

import pandas as pd
import glob
import os

tracking_folder = "/content/BoostTrack/tracking_results"
merged_file = "/content/BoostTrack/tracking_results/merged_tracking.csv"

# Only read files starting with 'bbox_log_' to avoid merging unrelated CSVs
all_files = glob.glob(os.path.join(tracking_folder, "bbox_log_*.csv"))

df_list = []
for file in all_files:
    df = pd.read_csv(file)
    seq_name = os.path.splitext(os.path.basename(file))[0].replace('bbox_log_', '')
    df['sequence'] = seq_name
    df_list.append(df)

merged_df = pd.concat(df_list, ignore_index=True)
merged_df.to_csv(merged_file, index=False)

print(f"[✓] Merged {len(df_list)} tracking CSVs into {merged_file} with {len(merged_df)} total rows.")

import glob
import os

tracking_folder = "/content/BoostTrack/tracking_results"
files = glob.glob(os.path.join(tracking_folder, "bbox_log_*.csv"))

print(f"Found {len(files)} files:")
for f in files:
    print(f)

import os

folder = "/content/BoostTrack/tracking_results"
files = os.listdir(folder)
print(f"Files in {folder}:")
for f in files:
    print(f)

import pandas as pd

df = pd.read_csv('/content/BoostTrack/tracking_results/MOT17-05-FRCNN.csv')
print(df)

import os
import pandas as pd

bbox_log_path = "/content/BoostTrack/bbox_log.csv"
output_dir = "/content/BoostTrack/preds"
os.makedirs(output_dir, exist_ok=True)

df = pd.read_csv(bbox_log_path)

# If 'video_name' column does not exist, assign a default name to all rows
if "video_name" not in df.columns:
    df["video_name"] = "default_sequence"

# Process each sequence separately
for seq in df["video_name"].unique():
    seq_df = df[df["video_name"] == seq].copy()

    # Convert bbox from (x1, y1, x2, y2) to (x, y, w, h)
    seq_df["x"] = seq_df["x1"]
    seq_df["y"] = seq_df["y1"]
    seq_df["w"] = seq_df["x2"] - seq_df["x1"]
    seq_df["h"] = seq_df["y2"] - seq_df["y1"]

    # Prepare DataFrame in MOTChallenge format
    mot_format = seq_df[["frame", "track_id", "x", "y", "w", "h", "confidence"]].copy()
    mot_format["class"] = -1
    mot_format["vis"] = -1
    mot_format["unused"] = -1

    pred_path = os.path.join(output_dir, f"{seq}.txt")
    mot_format.to_csv(pred_path, header=False, index=False)
    print(f"✅ Saved prediction for {seq} to {pred_path}")

import pandas as pd

# Load original bbox log
df = pd.read_csv("/content/BoostTrack/bbox_log.csv")

# Convert to MOT format
df["w"] = df["x2"] - df["x1"]
df["h"] = df["y2"] - df["y1"]

mot_df = df[["frame", "track_id", "x1", "y1", "w", "h", "confidence"]].copy()
mot_df["class"] = -1
mot_df["vis"] = -1
mot_df["dummy"] = -1

# Save to MOT format file
mot_df.to_csv("/content/BoostTrack/preds/default_sequence.txt", index=False, header=False)

import pandas as pd
import os

# Load your tracking log
bbox_log = pd.read_csv('/content/bbox_log_seq.csv')  # must contain: seq, frame, id, x, y, w, h, conf

# Create output folder
os.makedirs('preds', exist_ok=True)

# Group by sequence (e.g., MOT20-01, MOT20-02)
if 'seq' not in bbox_log.columns:
    print("Missing 'seq' column in bbox_log.csv. Please add it to associate rows with sequences.")
else:
    for seq_name, group in bbox_log.groupby('seq'):
        output_file = os.path.join('preds', f'{seq_name}.txt')

        with open(output_file, 'w') as f:
            for _, row in group.iterrows():
                line = f"{int(row['frame'])},{int(row['id'])},{row['x']:.2f},{row['y']:.2f},{row['w']:.2f},{row['h']:.2f},{row['conf']:.2f},-1,-1,-1\n"
                f.write(line)

        print(f"[✓] Wrote: {output_file}")





!git clone https://github.com/JonathonLuiten/TrackEval.git
!cd TrackEval
!pip install -r requirements.txt

!pip install numpy scipy matplotlib

!touch requirements.txt

!pip install -r requirements.txt

!pip install numpy scipy pycocotools matplotlib opencv-python scikit-image pytest Pillow tqdm tabulate

!python /content/TrackEval/scripts/run_mot_challenge.py

import os

# Create the seqmaps directory
seqmap_dir = "/content/TrackEval/data/gt/mot_challenge/seqmaps"
os.makedirs(seqmap_dir, exist_ok=True)

# MOT17-train sequences
mot17_seqs = [
    "MOT17-13-SDP", "MOT17-13-FRCNN", "MOT17-13-DPM",
    "MOT17-11-SDP", "MOT17-11-FRCNN", "MOT17-11-DPM",
    "MOT17-10-SDP", "MOT17-10-FRCNN", "MOT17-10-DPM",
    "MOT17-09-SDP", "MOT17-09-FRCNN", "MOT17-09-DPM",
    "MOT17-05-FRCNN", "MOT17-05-DPM",
    "MOT17-04-SDP", "MOT17-04-FRCNN", "MOT17-04-DPM",
    "MOT17-02-SDP", "MOT17-02-FRCNN", "MOT17-02-DPM"
]

# Save MOT17-train.txt
with open(os.path.join(seqmap_dir, "MOT17-train.txt"), "w") as f:
    f.write("\n".join(mot17_seqs))

# MOT20-train sequences
mot20_seqs = ["MOT20-01", "MOT20-02", "MOT20-03", "MOT20-05"]

# Save MOT20-train.txt
with open(os.path.join(seqmap_dir, "MOT20-train.txt"), "w") as f:
    f.write("\n".join(mot20_seqs))

!cat /content/TrackEval/data/gt/mot_challenge/seqmaps/MOT17-train.txt
!cat /content/TrackEval/data/gt/mot_challenge/seqmaps/MOT20-train.txt